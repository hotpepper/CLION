{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DatabaseConnections import *\n",
    "import params\n",
    "import pandas as pd\n",
    "import cPickle as cpickle\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import progressbar\n",
    "from operator import itemgetter\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db = PostgresDb(params.DB_HOST, params.DB_NAME) \n",
    "\n",
    "clear_output()\n",
    "print 'Connected to database {}'.format(params.DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Cleanup any files from previous run\n",
    "#### -- This will delete old data --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def reset(db, version):\n",
    "    tables = ['node_stnameft', 'lion', 'node', 'c_master_node',\n",
    "              'c_master_segs', 'C_Lion_%s' % version, 'C_Lion_Nodes_%s' % version, 'm']\n",
    "    for t in tables:\n",
    "        print 'Droping %s\\n' % t\n",
    "        db.query(\"DROP TABLE if exists %s\" % t)\n",
    "    return raw_input('Re-imported lion and nodes? <enter>\\n').upper()\n",
    "\n",
    "@timeDec\n",
    "def reset_current_version(db, version):\n",
    "    tables = ['node_stnameft', 'c_master_node',\n",
    "              'c_master_segs', 'C_Lion_%s' % version, 'C_Lion_Nodes_%s' % version, 'm']\n",
    "    for t in tables:\n",
    "        print 'Droping %s\\n' % t\n",
    "        db.query(\"DROP TABLE if exists %s\" % t)\n",
    "    # clean up exsiting tables \n",
    "    db.query(\"alter table lion drop column version\")\n",
    "    db.query(\"alter table lion drop column exclude\")\n",
    "    db.query(\"alter table lion drop column mft\")\n",
    "    db.query(\"alter table lion drop column masteridfrom\")\n",
    "    db.query(\"alter table lion drop column masteridto\")\n",
    "    \n",
    "    db.query(\"alter table node drop column version\")\n",
    "    db.query(\"alter table node drop column masterid\")\n",
    "    db.query(\"alter table node drop column is_int\")\n",
    "    print 'Done...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean out old versions of lion ?\n",
    "\n",
    "if raw_input('Delete and reimport old LION (1) or clean up existing LION (2)') == '1':\n",
    "    reset(db, params.VERSION)\n",
    "else:\n",
    "    reset_current_version(db, params.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import Roadbed Pointer List into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        read_data = f.read()\n",
    "    return read_data\n",
    "\n",
    "def split_to_rows(raw_data):\n",
    "    d = raw_data.split('\\n')\n",
    "    output = []\n",
    "    for row in d:\n",
    "        output.append(row.split(','))\n",
    "    return output\n",
    "\n",
    "def split_to_columns(data_rows):\n",
    "    data = []\n",
    "    # ['RPL_ID', 'SegmentIDG', 'SegmentIDR', 'RPC', 'NCI',\n",
    "    #         'NodeLevelF', 'NodeLevelT', 'R_FrNd', 'G_FrNd', 'R_ToNd', 'G_ToNd']\n",
    "    idn = 0\n",
    "    for row in data_rows:\n",
    "        if row != ['']:\n",
    "            # print row\n",
    "            idn += 1\n",
    "            g_seg = row[0][:7]\n",
    "            g_seg_typ = row[0][7]\n",
    "            r_seg = row[0][8:15]\n",
    "            rpc = row[0][16]\n",
    "            nci = row[0][18]\n",
    "            fnode_level_code = row[0][22]\n",
    "            tnode_level_code = row[0][26]\n",
    "            f_node_rb_seg = row[0][28:35]\n",
    "            f_node_g_seg = row[0][36:43]\n",
    "            t_node_rb_seg = row[0][44:51]\n",
    "            t_node_g_seg = row[0][52:59]\n",
    "            data.append([idn, g_seg, r_seg, rpc, nci, fnode_level_code, tnode_level_code,\n",
    "                         f_node_rb_seg, f_node_g_seg, t_node_rb_seg, t_node_g_seg])\n",
    "    return data\n",
    "\n",
    "def add_to_db(db, rpl, data):\n",
    "    # make sure table exists and is clean\n",
    "    db.query(\"\"\"DROP TABLE if exists {0};\n",
    "                    CREATE TABLE {0}\n",
    "                    (\n",
    "                      rpl_id bigint, segmentidg bigint, segmentidr bigint,\n",
    "                      rpc character varying(1), nci character varying(1),\n",
    "                      nodelevelf character varying(1), nodelevelt character varying(1),\n",
    "                      r_frnd bigint, g_frnd bigint, r_tond bigint, g_tond bigint\n",
    "                    );\n",
    "                \"\"\".format(rpl))\n",
    "    for row in data:\n",
    "        if row[0] != 'RPL_ID':\n",
    "            add_row(db, row)\n",
    "\n",
    "\n",
    "def add_row(db, row):\n",
    "    if row[0]:\n",
    "        db.query(\"\"\"INSERT INTO tbl_rpl (rpl_id, segmentidg, segmentidr, rpc, nci,nodelevelf,\n",
    "                        nodelevelt, r_frnd, g_frnd, r_tond, g_tond)\n",
    "                        VALUES (%s);\n",
    "                    \"\"\" % str(row)[1:-1])\n",
    "        print 'Added %s' % row[0]\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def add_rpl(db):\n",
    "    r_data = read_file(os.path.join(params.FOLDER, params.RPL_TXT))\n",
    "    dta = split_to_rows(r_data)\n",
    "    split_data = split_to_columns(dta)\n",
    "    add_to_db(db, params.RPL, split_data)\n",
    "\n",
    "add_rpl(db)\n",
    "query_to_table(db, \"select * from {} limit 10\".format(params.RPL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def save_dictionaries(io='OUT'):\n",
    "    \"\"\"write out the data in dictionaries, may only be useful for testing...\"\"\"\n",
    "    if io == 'OUT':\n",
    "        cpickle.dump(params.nodeStreetNames, open(os.path.join(params.FOLDER, \"nodeStreetNames.p\"), \"wb\"))\n",
    "        cpickle.dump(params.nodeIsIntersection, open(os.path.join(params.FOLDER, \"nodeIsIntersection.p\"), \"wb\"))\n",
    "        cpickle.dump(params.nodeNextSteps, open(os.path.join(params.FOLDER, \"nodeNextSteps.p\"), \"wb\"))\n",
    "        cpickle.dump(params.segmentBlocks, open(os.path.join(params.FOLDER, \"segmentBlocks.p\"), \"wb\"))\n",
    "        cpickle.dump(params.node_master, open(os.path.join(params.FOLDER, \"nodeMaster.p\"), \"wb\"))\n",
    "        cpickle.dump(params.clusterIntersections, open(os.path.join(params.FOLDER, \"clusterIntersections.p\"), \"wb\"))\n",
    "        cpickle.dump(params.streetSet, open(os.path.join(params.FOLDER, \"streetSet.p\"), \"wb\"))\n",
    "        cpickle.dump(params.mft1Dict, open(os.path.join(params.FOLDER, \"mft1Dict.p\"), \"wb\"))\n",
    "        cpickle.dump(params.altGraph, open(os.path.join(params.FOLDER, \"altGraph.p\"), \"wb\"))\n",
    "        cpickle.dump(params.mfts, open(os.path.join(params.FOLDER, \"mfts.p\"), \"wb\"))\n",
    "        cpickle.dump(params.coordFromMaster, open(os.path.join(params.FOLDER, \"coordFromMaster.p\"), \"wb\"))\n",
    "    else:\n",
    "        d1 = cpickle.load(open(os.path.join(params.FOLDER, \"nodeStreetNames.p\"), \"rb\"))\n",
    "        d2 = cpickle.load(open(os.path.join(params.FOLDER, \"nodeIsIntersection.p\"), \"rb\"))\n",
    "        d3 = cpickle.load(open(os.path.join(params.FOLDER, \"nodeNextSteps.p\"), \"rb\"))\n",
    "        d4 = cpickle.load(open(os.path.join(params.FOLDER, \"segmentBlocks.p\"), \"rb\"))\n",
    "        d5 = cpickle.load(open(os.path.join(params.FOLDER, \"nodeMaster.p\"), \"rb\"))\n",
    "        d6 = cpickle.load(open(os.path.join(params.FOLDER, \"clusterIntersections.p\"), \"rb\"))\n",
    "        d7 = cpickle.load(open(os.path.join(params.FOLDER, \"streetSet.p\"), \"rb\"))\n",
    "        d8 = cpickle.load(open(os.path.join(params.FOLDER, \"mft1Dict.p\"), \"rb\"))\n",
    "        d9 = cpickle.load(open(os.path.join(params.FOLDER, \"altGraph.p\"), \"rb\"))\n",
    "        d10 = cpickle.load(open(os.path.join(params.FOLDER, \"mfts.p\"), \"rb\"))\n",
    "        d11 = cpickle.load(open(os.path.join(params.FOLDER, \"coordFromMaster.p\"), \"rb\"))\n",
    "        return d1, d2, d3, d4, d5, d6, d7, d8, d9, d10, d11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preprocess \n",
    "## Set up data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def pre_process(db, lion, node, version, highways=False):\n",
    "    print 'Adding version number (%s)...\\n' % version\n",
    "    db.query(\"alter table %s add version varchar(50)\" % lion)\n",
    "    db.query(\"alter table %s add version varchar(50)\" % node)\n",
    "    db.query(\"update %s set version  = '%s'\" % (lion, version))\n",
    "    db.query(\"update %s set version  = '%s'\" % (node, version))\n",
    "    # add field for exclusion\n",
    "    db.query(\"alter table %s add exclude int\" % lion)\n",
    "    db.query(\"update %s set exclude  = 1\" % (lion)) # exclude everything\n",
    "    \n",
    "    print 'Adding master ID fields to tables...\\n'\n",
    "    db.query(\"alter table %s add column mft int, add column masteridfrom int, add column masteridto int\" % lion)\n",
    "    db.query(\"alter table %s add column masterid int\" % node)\n",
    "    db.query(\"alter table %s add column is_int int\" % node)\n",
    "    \n",
    "    print 'Creating node street name table (highways = %s)...\\n' % str(highways)\n",
    "    if highways:\n",
    "        db.query(\"\"\"\n",
    "                update {0} set exclude = 0  \n",
    "                where rb_layer in ('B', 'G') and featuretyp in ('0', '6', 'C') \n",
    "                and (nonped = 'D' or nonped is null)\n",
    "                and trafdir != 'P' and rw_type!='7' -- take out ped streets (not including step streets)\n",
    "                and street != 'UNNAMED STREET' \n",
    "                and street not like '%{1}%' and street not like '%{2}%'  and street not like '%{3}%'\n",
    "                \"\"\".format(lion, 'PED OVPS', 'PEDESTRIAN OVERPASS', 'PEDESTRIAN UNDERPASS'))\n",
    "        \n",
    "        db.query(\"\"\"\n",
    "                update {0} set exclude = 0  \n",
    "                where rb_layer in ('B', 'G') and featuretyp in ('0', '6', 'C') \n",
    "                and (nonped = 'V' and street = 'PELHAM PARKWAY')\n",
    "                and trafdir != 'P' and rw_type!='7' -- take out ped streets (not including step streets)\n",
    "                and street != 'UNNAMED STREET' \n",
    "                and street not like '%{1}%' and street not like '%{2}%' and street not like '%{3}%'\n",
    "                \"\"\".format(lion, 'PED OVPS', 'PEDESTRIAN OVERPASS', 'PEDESTRIAN UNDERPASS'))\n",
    "        \n",
    "        db.query(\"\"\"\n",
    "                update {0} set exclude = 0  \n",
    "                where nonped = 'V' and rb_layer in ('B', 'G') and street = 'EAST FORDHAM ROAD'\n",
    "                \"\"\".format(lion))\n",
    "        \n",
    "        db.query(\"\"\"\n",
    "                update {0} set exclude = 0  \n",
    "                where rb_layer in ('B', 'G') and featuretyp in ('0', '6', 'C') \n",
    "                and (nonped = 'V' and street = 'ROCKAWAY FREEWAY')\n",
    "                and street != 'UNNAMED STREET' \n",
    "                and street not like '%{1}%' and street not like '%{2}%'  and street not like '%{3}%'\n",
    "                \"\"\".format(lion, 'PED OVPS', 'PEDESTRIAN OVERPASS', 'PEDESTRIAN UNDERPASS'))\n",
    "        \n",
    "        db.query(\"\"\"drop table if exists node_stnameFT;\n",
    "                    create table node_stnameFT as (\n",
    "                    select node::int, street, 0 as master from (\n",
    "                        select nodeidfrom as node, street\n",
    "                        from {0} where exclude = 0\n",
    "                        group by nodeidfrom, street\n",
    "\n",
    "                        union\n",
    "\n",
    "                        select nodeidto as node, street\n",
    "                        from {0} where exclude = 0\n",
    "                        group by nodeidto, street\n",
    "                    ) as included );\"\"\".format(lion))\n",
    "    else:\n",
    "        db.query(\"\"\"update {0} set exclude = 0  \n",
    "                where rb_layer in ('B', 'G') and featuretyp in ('0', '6', 'C')\n",
    "                and trafdir != 'P' and rw_type!='7' -- take out ped streets (not including step streets)\n",
    "                and street != 'UNNAMED STREET' \n",
    "                and street not like '%{1}%' and street not like '%{2}%'  and street not like '%{3}%'\n",
    "                \"\"\".format(lion, 'PED OVPS', 'PEDESTRIAN OVERPASS', 'PEDESTRIAN UNDERPASS'))\n",
    "        \n",
    "        db.query(\"\"\"drop table if exists node_stnameFT;\n",
    "                    create table node_stnameFT as (\n",
    "                    select node::int, street, 0 as master\n",
    "                    from (\n",
    "                        select nodeidfrom as node, street\n",
    "                        from {0}\n",
    "                        where where exclude = 0\n",
    "                        group by nodeidfrom, street\n",
    "\n",
    "                        union\n",
    "\n",
    "                        select nodeidto as node, street\n",
    "                        from {0}\n",
    "                        where where exclude = 0\n",
    "                        group by nodeidto, street\n",
    "                        ) ft\n",
    "                    group by node, street)\n",
    "                \"\"\".format(lion))\n",
    "# Run preprocess\n",
    "pre_process(db, params.LION, params.NODE, params.VERSION, params.HIGHWAYS)\n",
    "# Check resutls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query_to_table(db, \"select * from node_stnameFT limit 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 2\n",
    "### Build data dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def de_suffix(name):  # todo fix e as part of east example\n",
    "    \"\"\"cleans up street names for less percise matches\"\"\"\n",
    "    d = {' WEST': ' DIR', ' EAST': ' DIR',\n",
    "         ' SOUTH': ' DIR', ' NORTH': ' DIR',\n",
    "         ' EXIT': ' DIR', ' ENTRANCE': ' DIR',\n",
    "         ' APPROACH': ' DIR', ' NORTHBOUND': ' DIR',\n",
    "         ' SOUTHBOUND': ' DIR', ' EASTBOUND': ' DIR',\n",
    "         ' WESTBOUND': ' DIR'}  # new needs to be tested!!!!\n",
    "    for i in d:\n",
    "        if name not in ('WEST STREET', 'SOUTH STREET', 'NORTH STREET', 'EAST STREET',\n",
    "                        'WEST AVENUE', 'SOUTH AVENUE', 'NORTH AVENUE', 'EAST AVENUE',\n",
    "                        'WEST BOULEVARD', 'SOUTH BOULEVARD', 'NORTH BOULEVARD', 'EAST BOULEVARD',\n",
    "                        'WEST LOOP', 'SOUTH LOOP', 'NORTH LOOP', 'EAST LOOP',\n",
    "                        'WEST DRIVE', 'SOUTH DRIVE', 'NORTH DRIVE', 'EAST DRIVE',\n",
    "                        'WEST ROAD', 'SOUTH ROAD', 'NORTH ROAD', 'EAST ROAD',\n",
    "                        'JUNIPER BOULEVARD NORTH', 'JUNIPER BOULEVARD SOUTH'\n",
    "                        'PROSPECT PARK WEST', 'AVENUE N', 'AVENUE S', 'AVENUE E',\n",
    "                        'AVENUE W',):\n",
    "            name = name.replace(i, d[i])\n",
    "    return name \n",
    "    \n",
    "@timeDec\n",
    "def node_names(db, nodeStreetNames):\n",
    "    data = db.query(\"select * from node_stnameFT\")\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for row in bar(data[0]):\n",
    "        node, street = row[0], de_suffix(row[1])\n",
    "        if node not in nodeStreetNames.keys():\n",
    "            nodeStreetNames[node] = set([street])\n",
    "        else:\n",
    "            nodeStreetNames[node].add(street)\n",
    "    return nodeStreetNames\n",
    "\n",
    "params.nodeStreetNames = {}\n",
    "params.nodeStreetNames = node_names(db, params.nodeStreetNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def intersection_binary_temp(db, node_table, lion):\n",
    "    \"\"\"Updates the is_int field in db\"\"\"\n",
    "    db.query(\"drop table if exists temp_int;\")\n",
    "    db.query(\"\"\"create table temp_int as (\n",
    "                    select nodeid, is_int, count(*) as cnt\n",
    "                    from (\n",
    "                        select nodeid, is_int, street\n",
    "                        from {0} n join {1} l \n",
    "                        on n.nodeid::int = l.nodeidfrom::int \n",
    "                        where exclude = 0\n",
    "                        union\n",
    "                        select nodeid, is_int, street\n",
    "                        from {0} n join {1} l \n",
    "                        on n.nodeid::int = l.nodeidto::int\n",
    "                        where exclude = 0                        \n",
    "                    ) as base\n",
    "                    group by nodeid, is_int\n",
    "                    having count(*) >1\n",
    "                );\"\"\".format(node_table, lion))\n",
    "    db.query(\"update {0} set is_int = -1 from temp_int where {0}.nodeid=temp_int.nodeid;\".format(node_table))\n",
    "    db.query(\"drop table temp_int;\")  \n",
    "\n",
    "intersection_binary_temp(db, params.NODE, params.LION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def intersection_highway_ramp_fix(db, node_table, lion):\n",
    "\n",
    "    # create highway ramp intersection table\n",
    "    db.query(\"\"\"\n",
    "               drop table if exists ramp_ints;\n",
    "                create table ramp_ints  as \n",
    "                select nodeidfrom, nodelevelf, count(*) \n",
    "                from (\n",
    "                    select nodeidfrom, nodelevelf, nonped from {0} \n",
    "                    where featuretyp in ('0', '6', 'C') and rb_layer in ('B','G') -- centerline vehicle only streets\n",
    "                    and street != 'UNNAMED STREET' and street not like '%PED OVPS%' and street not like '%PEDESTRIAN OVERPASS%'\n",
    "                    and exclude = 0\n",
    "                    union select nodeidto, nodelevelt, nonped from {0} \n",
    "                    where featuretyp in ('0', '6', 'C') and rb_layer in ('B','G') -- centerline vehicle only streets\n",
    "                    and street != 'UNNAMED STREET' and street not like '%PED OVPS%' and street not like '%PEDESTRIAN OVERPASS%'\n",
    "                    and exclude = 0\n",
    "                    \n",
    "                    union\n",
    "                     select nodeidfrom, nodelevelf, nonped from {0} \n",
    "                    where featuretyp in ('0', '6', 'C') and rb_layer in ('B','G') -- centerline vehicle only streets\n",
    "                    and street != 'UNNAMED STREET' and street not like '%PED OVPS%' and street not like '%PEDESTRIAN OVERPASS%'\n",
    "                    and (rw_type = '9' or segmenttyp = 'E') -- ramps\n",
    "                    union select nodeidto, nodelevelt, nonped from {0} \n",
    "                    where featuretyp in ('0', '6', 'C') and rb_layer in ('B','G') -- centerline vehicle only streets\n",
    "                    and street != 'UNNAMED STREET' and street not like '%PED OVPS%' and street not like '%PEDESTRIAN OVERPASS%'\n",
    "                    and (rw_type = '9' or segmenttyp = 'E') -- ramps\n",
    "                    \n",
    "                    -- special case for error in LION 16D !!!!\n",
    "                    union \n",
    "                    select nodeidfrom, nodelevelf, nonped from {0} \n",
    "                    where featuretyp in ('0', '6', 'C') and rb_layer in ('B','G') -- centerline vehicle only streets\n",
    "                    and street in ('QUEENS MIDTOWN TUNNEL APPROACH', 'QUEENS MIDTOWN TUNNEL EXIT')\n",
    "                    union select nodeidto, nodelevelt, nonped from {0} \n",
    "                    where featuretyp in ('0', '6', 'C') and rb_layer in ('B','G') -- centerline vehicle only streets\n",
    "                    and street in ('QUEENS MIDTOWN TUNNEL APPROACH', 'QUEENS MIDTOWN TUNNEL EXIT')\n",
    "                    -- special case for error in LION 16D !!!!\n",
    "                    \n",
    "                )i group by nodeidfrom, nodelevelf having count(*) > 1\n",
    "    \"\"\".format(lion))\n",
    "    # update main table\n",
    "    db.query(\"update {0} set is_int = -1 from ramp_ints where {0}.nodeid::int=ramp_ints.nodeidfrom::int;\".format(node_table))\n",
    "    \n",
    "\n",
    "intersection_highway_ramp_fix(db, params.NODE, params.LION)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "org,new = None, None\n",
    "if 79419 in params.nodeStreetNames.keys():\n",
    "    org = params.nodeStreetNames[79419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def intersection_highway_ramp_fix_part2(db, node_table, lion):\n",
    "    # update node_stnameFT\n",
    "    db.query(\"drop table if exists _temp_;\")\n",
    "    db.query(\"\"\"create table _temp_ as \n",
    "                select n.nodeid, street, 0 as master\n",
    "                from {0} l\n",
    "                join (\n",
    "                    select n.nodeid from {1} n\n",
    "                    left outer join node_stnameFT s\n",
    "                    on n.nodeid = s.node\n",
    "                    where n.is_int = -1\n",
    "                    and s.node is null\n",
    "                ) as n on l.nodeidfrom::int = n.nodeid\n",
    "                where exclude = 0\n",
    "                union\n",
    "                select n.nodeid, street, 0 as master\n",
    "                from {0} l\n",
    "                join (\n",
    "                    select n.nodeid from {1} n\n",
    "                    left outer join node_stnameFT s\n",
    "                    on n.nodeid = s.node\n",
    "                    where n.is_int = -1\n",
    "                    and s.node is null\n",
    "                ) as n on l.nodeidto::int = n.nodeid\n",
    "                where exclude = 0\n",
    "                \"\"\".format(lion, node_table))\n",
    "    db.query(\"insert into node_stnameFT select * from _temp_;\")\n",
    "    db.query(\"drop table if exists _temp_;\")\n",
    "    # update node_stnameFT\n",
    "#     db.query(\"\"\"insert into node_stnameFT \n",
    "#                     select n.nodeid, street, 0 as master\n",
    "#                     from {0} l\n",
    "#                     join (\n",
    "#                         select n.nodeid from {1} n\n",
    "#                         left outer join node_stnameFT s\n",
    "#                         on n.nodeid = s.node\n",
    "#                         where n.is_int = -1\n",
    "#                         and s.node is null\n",
    "#                     ) as n on l.nodeidfrom::int = n.nodeid\n",
    "#                     where exclude = 0\n",
    "#                     union\n",
    "#                     select n.nodeid, street, 0 as master\n",
    "#                     from {0} l\n",
    "#                     join (\n",
    "#                         select n.nodeid from {1} n\n",
    "#                         left outer join node_stnameFT s\n",
    "#                         on n.nodeid = s.node\n",
    "#                         where n.is_int = -1\n",
    "#                         and s.node is null\n",
    "#                     ) as n on l.nodeidto::int = n.nodeid\n",
    "#                     where exclude = 0\n",
    "#                     \"\"\".format(lion, node_table))\n",
    "#     db.query(\"drop table ramp_ints;\")\n",
    "    # clean up\n",
    "\n",
    "# run ramp intersectio patch\n",
    "intersection_highway_ramp_fix_part2(db, params.NODE, params.LION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Update street name intersection data for ramps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_ramp_names_to_ints(db, lion):\n",
    "    db.query(\"\"\"\n",
    "                insert into node_stnameFT\n",
    "                select n.node, l.street, n.master\n",
    "                from node_stnameFT n\n",
    "                join ramp_ints r on n.node::int = r.nodeidfrom::int\n",
    "                join (\n",
    "                    select r.nodeidfrom, l.street\n",
    "                    from ramp_ints r\n",
    "                    join {0} l on r.nodeidfrom = l.nodeidfrom\n",
    "                    union\n",
    "                    select r.nodeidfrom, l.street\n",
    "                    from ramp_ints r\n",
    "                    join {0} l on r.nodeidfrom = l.nodeidto\n",
    "                ) l on n.node::int = l.nodeidfrom::int and n.street != l.street\n",
    "            \"\"\".format(lion))\n",
    "\n",
    "\n",
    "\n",
    "add_ramp_names_to_ints(db, params.LION)\n",
    "# regenerate streetnames with new ramp names\n",
    "params.nodeStreetNames = node_names(db, params.nodeStreetNames)\n",
    "\n",
    "print params.nodeStreetNames[79419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if 79419 in params.nodeStreetNames.keys():\n",
    "    new = params.nodeStreetNames[79419]\n",
    "print org, new, org == new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def get_double_blocks(db, lion, node_table):\n",
    "    # get problem nodes where the blocks involved have more than 1 street name\n",
    "    db.query(\"\"\"drop table if exists doubles; \n",
    "                create table doubles as (\n",
    "                    select nf::int, nt::int, count(street)\n",
    "                    from (\n",
    "                        select  nodeidfrom as nf, nodeidto as nt, street\n",
    "                        from {0}\n",
    "                        where exclude = 0 or (rw_type = '9' or segmenttyp = 'E') -- ramps\n",
    "                        group by  nodeidfrom, nodeidto, street\n",
    "                    union\n",
    "                        select  nodeidto as nf, nodeidfrom as nt, street\n",
    "                        from {0}\n",
    "                        where exclude = 0 or (rw_type = '9' or segmenttyp = 'E') -- ramps\n",
    "                        group by  nodeidfrom, nodeidto, street\n",
    "                    ) as t\n",
    "                    group by nf, nt\n",
    "                    having count(street) > 1)\"\"\".format(lion))\n",
    "    \n",
    "    # then those nodes need to have > 2 streets to be an intersection. \n",
    "    db.query(\"\"\"create table temp_int as (\n",
    "                    select nodeid, is_int, count(*) as cnt from (\n",
    "                            select nodeid, is_int, street\n",
    "                            from (\n",
    "                                    select nodeid, is_int, street\n",
    "                                    from {0} \n",
    "                                    join {1} on st_dwithin({0}.geom, {1}.geom,1)\n",
    "                                    where exclude = 0 or (rw_type = '9' or segmenttyp = 'E') -- ramps\n",
    "                                    group by nodeid, is_int, street\n",
    "                            ) as base, \n",
    "                    doubles\n",
    "                    where nodeid = nf or nodeid = nt\n",
    "                            group by nodeid, is_int, street\n",
    "                    ) as grp group by nodeid, is_int\n",
    "                            having count(*) < 3\n",
    "                );\"\"\".format(node_table, lion))\n",
    "    # update revised nodes\n",
    "    db.query(\"\"\"update %s as n\n",
    "                    set is_int = Null\n",
    "                    from temp_int\n",
    "                    where n.nodeid =temp_int.nodeid\n",
    "                    and n.is_int = -1\n",
    "                    ;\"\"\" % node_table)\n",
    "    db.query(\"drop table temp_int; drop table doubles;\")\n",
    "\n",
    "\n",
    "# fix locations with double segments...\n",
    "get_double_blocks(db, params.LION, params.NODE)  # 149.80 sec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def intersection_binary_dict(db, node_table, nodeIsIntersection):\n",
    "    # get data from db into local dictionary\n",
    "    data = db.query(\"select nodeid, is_int from %s \" % node_table)  # where is_int =-1\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for i in bar(data[0]):\n",
    "        if i[1] == -1:\n",
    "            nodeIsIntersection[int(i[0])] = True\n",
    "        else:\n",
    "            nodeIsIntersection[int(i[0])] = False\n",
    "    del data\n",
    "    print 'Dictionary updated'\n",
    "    return nodeIsIntersection\n",
    "\n",
    "params.nodeIsIntersection = intersection_binary_dict(db, params.NODE, params.nodeIsIntersection)\n",
    "# # run this again for highway ramps\n",
    "# params.nodeStreetNames = node_names(db, params.nodeStreetNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# nodeStreetNames = {}\n",
    "# # run this again for highway ramps\n",
    "# nodeStreetNames = node_names(db, params.nodeStreetNames)\n",
    "#print nodeStreetNames[43709]\n",
    "#print params.nodeStreetNames[43709]\n",
    "\n",
    "# print nodeStreetNames[46444] # 41 ave and bqe not intersection\n",
    "# print params.nodeStreetNames[46444] # 41 ave and bqe not intersection\n",
    "#print params.nodeIsIntersection[46444] # 41 ave and bqe not intersection\n",
    "\n",
    "\n",
    "#print nodeStreetNames[46404] # northern and bqe exit\n",
    "print params.nodeStreetNames[46404] # northern and bqe exit\n",
    "print params.nodeIsIntersection[46404] # northern and bqe exit\n",
    "\n",
    "\n",
    "print params.nodeIsIntersection[35485] # Rockaway Freeway and Beach 59 St\n",
    "print params.nodeStreetNames[35485] # Rockaway Freeway and Beach 59 St"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def add_to_graph(street, node1, node2, nodeNextSteps):\n",
    "    \"\"\"checks if segment is in the graph adds it if not\"\"\"\n",
    "    if node1 not in nodeNextSteps.keys():\n",
    "        nodeNextSteps[node1] = {street: set([node2])}\n",
    "    else:\n",
    "        if street not in nodeNextSteps[node1].keys():\n",
    "            nodeNextSteps[node1][street] = set([node2])\n",
    "        else:\n",
    "            nodeNextSteps[node1][street].add(node2)\n",
    "    return nodeNextSteps\n",
    "\n",
    "\n",
    "@timeDec\n",
    "def graph(db, lion, nodeNextSteps, highways=False):\n",
    "    \"\"\"Graph the street network\"\"\"\n",
    "    if highways:\n",
    "        segs = db.query(\"\"\"select street, segmentid, nodeidfrom, nodeidto \n",
    "                        from {0} where exclude = 0\n",
    "                        \"\"\".format(lion))\n",
    "    else:\n",
    "        segs = db.query(\"\"\"select street, segmentid, nodeidfrom, nodeidto \n",
    "                        from {0} where exclude = 0\n",
    "                        \"\"\".format(lion))\n",
    "\n",
    "    print 'Done with DB'\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for row in bar(segs[0]):\n",
    "        street, segmentid, nodeidfrom, nodeidto = row[0], row[1], int(row[2]), int(row[3])\n",
    "        nodeNextSteps = add_to_graph(street, nodeidfrom, nodeidto, nodeNextSteps)\n",
    "        nodeNextSteps = add_to_graph(street, nodeidto, nodeidfrom, nodeNextSteps)\n",
    "    del segs\n",
    "    return nodeNextSteps\n",
    "\n",
    "\n",
    "params.nodeNextSteps = graph(db, params.LION, params.nodeNextSteps, params.HIGHWAYS)  # 179.22 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Break point - save progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dictionaries('OUT')  # 19.72 sec\n",
    "# params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 3\n",
    "### Build simple blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run to read saved data back into memory \n",
    "\n",
    "params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# simple graph search for grouping blocks\n",
    "\n",
    "def go_to_end(street, done, todo, nodeIsIntersection=params.nodeIsIntersection, nodeNextSteps=params.nodeNextSteps):\n",
    "    # anything left in the queue?\n",
    "    if len(todo) == 0:\n",
    "        # you're done exit\n",
    "        return done\n",
    "    else:\n",
    "        # get new starting point\n",
    "        start = todo.pop()\n",
    "        # add it to the visited nodes\n",
    "        done.append(start)\n",
    "        # make sure it is not an ending point\n",
    "        if not nodeIsIntersection[start]:\n",
    "            # see where we can go from here\n",
    "            for i in nodeNextSteps[start][street]:\n",
    "                # make sure we haven't done it yet\n",
    "                if i not in done:\n",
    "                    # add it to the queue\n",
    "                    todo.add(i)\n",
    "        return go_to_end(street, done, todo)\n",
    "    \n",
    "@timeDec\n",
    "def search(nodeStreetNames, streetSet, nodeIsIntersection, nodeNextSteps):\n",
    "    \"\"\"gets intersection to intersection segments or collection of segments\"\"\"\n",
    "    for startNode in nodeStreetNames.keys():\n",
    "        if nodeIsIntersection[startNode]:\n",
    "            for street in nodeNextSteps[startNode].keys():\n",
    "                queue = list(nodeNextSteps[startNode][street])\n",
    "                while len(queue) > 0:\n",
    "                    to_node = queue.pop()\n",
    "                    streetSet.append(go_to_end(street, [startNode], set([to_node])))\n",
    "    return nodeStreetNames, streetSet\n",
    "\n",
    "params.nodeStreetNames, params.streetSet = search(params.nodeStreetNames, params.streetSet, params.nodeIsIntersection, params.nodeNextSteps)\n",
    "\n",
    "print '\\nnodeStreetNames(dict) sample: {{{0} : {1}}}'.format(params.nodeStreetNames.keys()[50], \n",
    "                                                             params.nodeStreetNames[params.nodeStreetNames.keys()[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nodeStreetNames, streetSet, nodeIsIntersection, nodeNextSteps = params.nodeStreetNames, params.streetSet, params.nodeIsIntersection, params.nodeNextSteps\n",
    "\n",
    "for startNode in nodeStreetNames.keys():\n",
    "        if nodeIsIntersection[startNode]:\n",
    "            for street in nodeNextSteps[startNode].keys():\n",
    "                queue = list(nodeNextSteps[startNode][street])\n",
    "                while len(queue) > 0:\n",
    "                    to_node = queue.pop()\n",
    "                    streetSet.append(go_to_end(street, [startNode], set([to_node])))\n",
    "\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_csv(out_file, data_to_write, header=None, delim=','):\n",
    "    row_cnt = 0\n",
    "    with open(out_file, 'wb') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=delim)\n",
    "        if header:\n",
    "            writer.writerow(header)\n",
    "        for row in data_to_write:\n",
    "            writer.writerow(row)  # this writes the rows to the csv file row needs to be a list\n",
    "            row_cnt += 1\n",
    "    return str(row_cnt) + \" rows were written to \" + str(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print 'Starting...\\n'\n",
    "@timeDec\n",
    "def mft_round1(db, lion, altGraph, streetSet, mft1Dict, folder, highways=False):\n",
    "    \"\"\"gets simplest master segments based on from to nodes, intersections only\"\"\"\n",
    "    sql = \"\"\"select segmentid, nodeidfrom, nodeidto\n",
    "            from {0} where exclude = 0\n",
    "            group by segmentid, nodeidfrom, nodeidto\"\"\".format(lion)\n",
    "\n",
    "    data = db.query(sql)\n",
    "    # build local dict of seg node ids from-to to build mft\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for row in bar(data[0]):\n",
    "        # build up simple graph\n",
    "        # node : [[other node , segid], [other node , segid]]\n",
    "        segment, fromid, toid = row\n",
    "        if int(fromid) not in altGraph.keys():\n",
    "            altGraph[int(fromid)] = [[int(toid), segment]]\n",
    "        else:\n",
    "            altGraph[int(fromid)].append([int(toid), segment])\n",
    "\n",
    "        if int(toid) not in altGraph.keys():\n",
    "            altGraph[int(toid)] = [[int(fromid), segment]]\n",
    "        else:\n",
    "            altGraph[int(toid)].append([int(fromid), segment])\n",
    "    print 'done graphing\\n'\n",
    "    mft = 0\n",
    "    to_write_out = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for block in bar(streetSet):  # streetSet is a set of nodes that together make up a block\n",
    "        if block:\n",
    "            #print mft\n",
    "            #clear_output()\n",
    "            mft += 1\n",
    "            for node in block:\n",
    "                for pair in altGraph[node]:\n",
    "                    if pair[0] in block:  # both ends of the street are in the block\n",
    "                        if mft not in mft1Dict.keys():\n",
    "                            mft1Dict[mft] = []\n",
    "                        mft1Dict[mft].append(pair[1])\n",
    "                        to_write_out.append([mft, pair[1]])\n",
    "    print 'Writing out csv\\n'\n",
    "    write_csv(os.path.join(folder, \"mft.csv\"), to_write_out, ['mft', 'segment'])  \n",
    "    db.query('drop table if exists tempMaster; CREATE TABLE tempMaster (mft varchar(10), seg varchar(10))')\n",
    "    return altGraph\n",
    "\n",
    "params.altGraph = mft_round1(db,  params.LION, params.altGraph,  params.streetSet, params.mft1Dict, \n",
    "                             params.FOLDER, params.HIGHWAYS)  # 1367.67 sec\n",
    "\n",
    "print '\\naltGraph(dict) sample: {{{0} : {1}}}'.format(params.altGraph.keys()[50], \n",
    "                                                             params.nodeStreetNames[params.altGraph.keys()[50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import_table(db, 'tempMaster', os.path.join(params.FOLDER, 'mft.csv'))\n",
    "# raw_input(\"\"\"PG Console \\n\\n \\copy tempMaster FROM '%s\\mft.csv' DELIMITERS ',' CSV HEADER;\\n\\nDone?\"\"\" % params.FOLDER)\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def add_temp_table(db, lion):  # Assumes that tempMaster is imported\n",
    "    db.query(\"\"\"update %s as l\n",
    "                    set mft = t.mft::int\n",
    "                    from tempmaster as t\n",
    "                    where l.segmentid =t.seg\"\"\" % lion)\n",
    "    db.query(\"drop table tempmaster\")\n",
    "\n",
    "add_temp_table(db, params.LION)  # 35.44 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dictionaries('OUT')  # 10.07 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 4\n",
    "### Build simple intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run to read saved data back into memory \n",
    "\n",
    "params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def add_master_place_to_street_names(nodeStreetNames, nodeIsIntersection):\n",
    "    to_remove = []\n",
    "    for n in nodeStreetNames:\n",
    "        if nodeIsIntersection[n]:  # only want intersection nodes\n",
    "            # reformat the dict to have a spot for master id\n",
    "            nodeStreetNames[n] = [nodeStreetNames[n], 0]\n",
    "        else:\n",
    "            # store non-intersections to remove latter\n",
    "            to_remove.append(n)\n",
    "    for i in to_remove:\n",
    "        # not intersection remove it from dictionary\n",
    "        del nodeStreetNames[i]\n",
    "    return nodeStreetNames\n",
    "\n",
    "params.nodeStreetNames = add_master_place_to_street_names(params.nodeStreetNames, params.nodeIsIntersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def street_name_key(street_set):\n",
    "    street_set = list(street_set)\n",
    "    street_set.sort()\n",
    "    street_set = str(street_set)\n",
    "    return street_set[1:-1]\n",
    "\n",
    "@timeDec\n",
    "def intersection_cluster_dict(nodeStreetNames, clusterIntersections):\n",
    "    # get street names by intersetion\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for node in bar(nodeStreetNames.keys()):\n",
    "        # order the street names\n",
    "        street_key = street_name_key(nodeStreetNames[node][0])\n",
    "        # if not in dictionary, add street name set\n",
    "        if street_key not in clusterIntersections.keys():\n",
    "            clusterIntersections[street_key] = [set(), 0]\n",
    "        # add node to the street name set dict\n",
    "        clusterIntersections[street_key][0].add(node)\n",
    "    return clusterIntersections\n",
    "\n",
    "params.clusterIntersections = intersection_cluster_dict(params.nodeStreetNames, params.clusterIntersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def master_intersection_first_pass(clusterIntersections, node_master):\n",
    "    master = 0\n",
    "    for street_set in clusterIntersections.keys():\n",
    "        master += 1\n",
    "        # add masterid to each set of street names\n",
    "        clusterIntersections[street_set][-1] = master\n",
    "        # update node: master dict\n",
    "        for node in clusterIntersections[street_set][0]:\n",
    "            node_master[node] = master\n",
    "    return clusterIntersections, node_master\n",
    "\n",
    "params.clusterIntersections, params.node_master = master_intersection_first_pass(params.clusterIntersections, params.node_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# master = \"'QUEENS PLAZA DIR'\"\n",
    "# #master = \"'PEDESTRIAN OVERPASS'\"\n",
    "# node = 82294\n",
    "# print params.clusterIntersections[master]\n",
    "# print params.nodeStreetNames[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def check_distance(db, node_table, folder, clusterIntersections):\n",
    "    tolerance = 1000  # used to be 300.........\n",
    "    data = db.query(\"select nodeid, st_x(geom), st_y(geom) from %s where is_int=-1\" % node_table)\n",
    "    loc = {}\n",
    "    # get geometry\n",
    "    for row in data[0]:\n",
    "        node, x, y = row\n",
    "        loc[node] = [x, y]\n",
    "    # save the loc table for later\n",
    "    cpickle.dump(loc, open(os.path.join(folder, \"loc.p\"), \"wb\"))\n",
    "\n",
    "    problems = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for master in bar(clusterIntersections.keys()):\n",
    "        print master \n",
    "        \n",
    "        # look for sets 2 nodes\n",
    "        if len(clusterIntersections[master][0]) > 1:\n",
    "            # get node's geom and check dist\n",
    "            # n1, n2 = list(clusterIntersections[master][0])[:2]\n",
    "            for pair in itertools.product(list(clusterIntersections[master][0]), repeat=2):\n",
    "                n1, n2 = pair\n",
    "                if distance(loc[n1][0], loc[n1][1], loc[n2][0], loc[n2][1]) > tolerance:\n",
    "                    problems.append(master)\n",
    "        clear_output()\n",
    "    return problems\n",
    "\n",
    "problems = check_distance(db, params.NODE, params.FOLDER, params.clusterIntersections)\n",
    "# sample\n",
    "query_to_table(db, \"select nodeid, st_x(geom), st_y(geom) from %s where is_int=-1 limit 10\" % params.NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# @timeDec\n",
    "def update_problem_groups(problems, neighbors, node_master):\n",
    "    for problem in problems:\n",
    "        pcts = problem.keys()\n",
    "        # simple case\n",
    "        if len(pcts) == 2:\n",
    "            if pcts[1] not in neighbors[pcts[0]]:  # pcts are not neighbors so update\n",
    "                mx = get_max_master(node_master)\n",
    "                for node in problem[pcts[1]]:\n",
    "                    node_master[node] = mx + 1\n",
    "                    # complex case with more than 2 pcts for now assume its a problem and update\n",
    "                    # come back to this if becomes messy\n",
    "        for pct in pcts:\n",
    "            mx = get_max_master(node_master)\n",
    "            for node in problem[pct]:\n",
    "                node_master[node] = mx + 1\n",
    "    return node_master\n",
    "\n",
    "def get_max_master(node_master):\n",
    "    # returns the largest master nodeid in the dict\n",
    "    mx_master = 0\n",
    "    for n in node_master.keys():\n",
    "        if node_master[n] > mx_master:\n",
    "            mx_master = node_master[n]\n",
    "    return mx_master\n",
    "\n",
    "@timeDec\n",
    "def check_problem_pcts(db, problems, node_table, lion_table, precinct_table, clusterIntersections, node_master):\n",
    "    # make lookup table\n",
    "    db.query(\"drop table if exists c_intersection_name\")\n",
    "    # this fails if all the streets' connect to the node are \"from\" or if all the streets' connect to the node are \"to\"\n",
    "    db.query(\"\"\"create table c_intersection_name as (\n",
    "                    select nodeid::int as nodeid, precinct, l.street as street1, ll.street as street2\n",
    "                    from {0} as n\n",
    "                    join {1} as l on l.nodeidfrom::int=nodeid::int\n",
    "                    join {1} as ll on ll.nodeidto::int=nodeid::int\n",
    "                    join {2} as p on st_within(n.geom, p.geom) \n",
    "                    where l.street !=ll.street\n",
    "                    )\"\"\".format(node_table, lion_table, precinct_table))\n",
    "    # store locally\n",
    "    lookup = {}\n",
    "    # sample \n",
    "    print query_to_table(db, \"select nodeid, precinct from c_intersection_name limit 10\")\n",
    "    \n",
    "    data = db.query(\"select nodeid, precinct from c_intersection_name\")\n",
    "    for row in data[0]:\n",
    "        node, pct = row\n",
    "        lookup[node] = pct\n",
    "    # check if precincts are neighbors (boundary issues)\n",
    "    data = db.query(\"\"\"select p1.precinct, p2.precinct\n",
    "                    from {0} as p1\n",
    "                    join {0} as p2\n",
    "                    on st_intersects(p1.geom, p2.geom)\n",
    "                    \"\"\".format(precinct_table))\n",
    "    neighbors = {}\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for row in bar(data[0]):\n",
    "        p1, p2 = row\n",
    "        if p1 not in neighbors:\n",
    "            neighbors[p1] = set()\n",
    "        neighbors[p1].add(p2)\n",
    "\n",
    "    to_update = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for problem in bar(problems):\n",
    "        rev_lookup = {}\n",
    "        for node in clusterIntersections[problem][0]:\n",
    "            if node in lookup.keys():  # known failure for 62493 all streets are \"from\"\n",
    "                if lookup[node] not in rev_lookup:\n",
    "                    rev_lookup[lookup[node]] = set()\n",
    "                rev_lookup[lookup[node]].add(node)\n",
    "        if len(rev_lookup) > 1:\n",
    "            to_update.append(rev_lookup)\n",
    "    node_master = update_problem_groups(to_update, neighbors, node_master)\n",
    "    return node_master\n",
    "\n",
    "params.node_master = check_problem_pcts(db, problems, params.NODE, params.LION, \n",
    "                                        params.PRECINCTS, params.clusterIntersections, params.node_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dictionaries('OUT')  # 10.07 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nodes = [46298,46393,46398,46402,46404,46406,46408,67047,76634,76638,76662,83615,\n",
    "         96229,9034370,9034372,9034373,9039520,9039521,9039522,9039525,9039527,9039528]\n",
    "\n",
    "def get_center(db, nodes):\n",
    "    # get map center \n",
    "    data, col = db.query(\"\"\"select\n",
    "                        st_y(st_transform(st_centroid(st_union(geom)),4326)), \n",
    "                        st_x(st_transform(st_centroid(st_union(geom)),4326))\n",
    "                        from node where nodeid in ({})\"\"\".format(str(nodes)[1:-1]))\n",
    "    cent_ln, cent_lt = data[0]\n",
    "    return cent_ln, cent_lt \n",
    "\n",
    "def map_nodes_is_int(db, nodes):\n",
    "    cent_ln, cent_lt  = get_center(db, nodes) \n",
    "    # create map object \n",
    "    Map = folium.Map(location=[cent_ln,cent_lt], \n",
    "                       tiles='Stamen Terrain',\n",
    "                       zoom_start=18)\n",
    "    # get nodes geom\n",
    "    data, col = db.query(\"\"\"select nodeid, is_int, \n",
    "                         st_y(st_transform(geom, 4326)) as y, \n",
    "                         st_x(st_transform(geom, 4326)) as x \n",
    "                         from node where nodeid in ({})\"\"\".format(str(nodes)[1:-1]))\n",
    "    # add nodes to map\n",
    "    for (node, is_int, lon, lat) in data:\n",
    "        if is_int == -1:\n",
    "            c = 'red'\n",
    "        else:\n",
    "            c = '#3186cc'\n",
    "        folium.CircleMarker(location=[lon, lat], \n",
    "                        radius=10,\n",
    "                        popup='point {}'.format(node), \n",
    "                        color=c,\n",
    "                        fill_color='#3186cc').add_to(Map)\n",
    "    #display map \n",
    "    return Map\n",
    "map_nodes_is_int(db, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nodes = [41313,41315,41317,41318,41375,41376,41378,81321,82136,82293,82294,82342,82952,\n",
    "         83000,90111,97255,97256,97650,97651,97653,97715,98042,98230,98238,98240,98407,\n",
    "         98408,99618,99619,99620,99637,99639,99640,106008,106009,106010,106011,9039786,\n",
    "         9039810,9039811,9039812,9039813,9039814,9039815,9039826,9039827,9039828,9039829]\n",
    "\n",
    "def get_center(db, nodes):\n",
    "    # get map center \n",
    "    data, col = db.query(\"\"\"select\n",
    "                        st_y(st_transform(st_centroid(st_union(geom)),4326)), \n",
    "                        st_x(st_transform(st_centroid(st_union(geom)),4326))\n",
    "                        from node where nodeid in ({})\"\"\".format(str(nodes)[1:-1]))\n",
    "    cent_ln, cent_lt = data[0]\n",
    "    return cent_ln, cent_lt \n",
    "\n",
    "def map_nodes_is_int(db, nodes):\n",
    "    cent_ln, cent_lt  = get_center(db, nodes) \n",
    "    # create map object \n",
    "    Map = folium.Map(location=[cent_ln,cent_lt], \n",
    "                       tiles='Stamen Terrain',\n",
    "                       zoom_start=18)\n",
    "    # get nodes geom\n",
    "    data, col = db.query(\"\"\"select nodeid, is_int, masterid,\n",
    "                         st_y(st_transform(geom, 4326)) as y, \n",
    "                         st_x(st_transform(geom, 4326)) as x \n",
    "                         from node where nodeid in ({})\"\"\".format(str(nodes)[1:-1]))\n",
    "    # add nodes to map\n",
    "    for (node, is_int, master, lon, lat) in data:\n",
    "        if is_int == -1:\n",
    "            c = 'red'\n",
    "        else:\n",
    "            c = '#3186cc'\n",
    "        folium.CircleMarker(location=[lon, lat], \n",
    "                        radius=10,\n",
    "                        popup='point {}'.format(master), \n",
    "                        color=c,\n",
    "                        fill_color=c).add_to(Map)\n",
    "    #display map \n",
    "    return Map\n",
    "map_nodes_is_int(db, nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 5\n",
    "### Build simple intersections 2 near by nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run to read saved data back into memory \n",
    "\n",
    "params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def near_nodes(db, node_table, search_distance, node):\n",
    "    # get nodes within search distance of a given node\n",
    "    nds = db.query(\"\"\"select nodeid::int\n",
    "                    from {0} as nn,\n",
    "                    (\n",
    "                            select geom \n",
    "                            from {0} \n",
    "                            where nodeid = {1}\n",
    "                    ) as base\n",
    "                    where st_dwithin(nn.geom, base.geom, {2})\n",
    "                    and nodeid != {1}\n",
    "                    and is_int = -1\n",
    "                    \"\"\".format(node_table, node, search_distance))\n",
    "    return [n[0] for n in nds[0]]\n",
    "\n",
    "def get_best_master(node_master, master1, master2):\n",
    "    # find the master with more nodes already associated with it\n",
    "    mm = {master1: 0, master2: 0}\n",
    "    for node in node_master.keys():\n",
    "        if node_master[node] == master1:\n",
    "            mm[master1] += 1\n",
    "        elif node_master[node] == master2:\n",
    "            mm[master2] += 1\n",
    "        else:\n",
    "            pass\n",
    "    if mm[master1] > mm[master2]:\n",
    "        return master1\n",
    "    else:\n",
    "        return master2\n",
    "\n",
    "@timeDec \n",
    "def near_by_simple(db, node_table, node_master, search_distance):\n",
    "    # get all nodes within seach distance\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for node in bar(node_master.keys()):\n",
    "        n_nodes = near_nodes(db, node_table, search_distance, node)\n",
    "        for n in n_nodes:\n",
    "            # go through those nodes\n",
    "            new_master = get_best_master(node_master, node_master[n], node_master[node])  # put org master 2nd as will default in tie\n",
    "            # apply the biggest masterid to the node in question\n",
    "            node_master[node] = new_master\n",
    "            # apply the biggest masterid to all nodes in question\n",
    "            node_master[n] = new_master\n",
    "    return node_master\n",
    "            \n",
    "params.node_master = near_by_simple(db, params.NODE, params.node_master, 75)  # 1619.62 sec #26 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dictionaries('OUT')  # 10.07 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 6\n",
    "### Build simple intersections from small triangles \n",
    "irregrualr intersections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run to read saved data back into memory \n",
    "\n",
    "params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def closest_n(altGraph, nodeIsIntersection, loc, node, n):\n",
    "    dl = []\n",
    "    x, y = loc[node]  # starting position\n",
    "    for l in altGraph[node]:\n",
    "        # get coordinates of other end of each seg at start node\n",
    "        if nodeIsIntersection[l[0]]:\n",
    "            x1, y1 = loc[l[0]]\n",
    "            d = distance(x, y, x1, y1)\n",
    "            # add distance and node to list\n",
    "            dl.append([d, l[0]])\n",
    "    z = sorted(dl, key=itemgetter(0))\n",
    "    # return closest N nodes with their distances\n",
    "    return z[:n]\n",
    "\n",
    "@timeDec\n",
    "def triangle(folder, node_master, altGraph, nodeIsIntersection, triangle_dist=150, n=2):\n",
    "    # load in the location dict\n",
    "    loc = cpickle.load(open(os.path.join(folder, \"loc.p\"), \"rb\"))\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for node in bar(node_master.keys()):\n",
    "        # for each node get the closest 2\n",
    "        near = closest_n(altGraph, nodeIsIntersection, loc, node, n)\n",
    "        # if the furthest near node is within tolerance\n",
    "        if len(near) > 1:\n",
    "            if near[-1][0] <= triangle_dist:\n",
    "                # check can get to each in 1 hop\n",
    "                # set of 2 closest is subset of nodes that are 1 hop in graph\n",
    "                # clean up for double segs (vertical topography?)\n",
    "                sn = set(n[1] for n in near)\n",
    "                if len(sn) > 1:\n",
    "                    a, b = set(n[1] for n in near)\n",
    "                    if a in set(n[0] for n in altGraph[b]):\n",
    "                        # if set(n[1] for n in near).issubset(set(n[0] for n in altGraph[node])):\n",
    "                        # should be 1 master\n",
    "                        for othernode in set(n[1] for n in near):\n",
    "                            # go through those nodes\n",
    "                            new_master = get_best_master(node_master,\n",
    "                                node_master[othernode], node_master[node])  # put org master 2nd as will default in tie\n",
    "                            # apply the biggest masterid to the node in question\n",
    "                            node_master[node] = new_master\n",
    "                            node_master[othernode] = new_master\n",
    "    return node_master\n",
    "\n",
    "params.node_master = triangle(params.FOLDER, params.node_master, params.altGraph, params.nodeIsIntersection, 150, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dictionaries('OUT')  # 10.07 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 7\n",
    "### update database intersections and build master segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run to read saved data back into memory \n",
    "\n",
    "params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@timeDec\n",
    "def update_db_nodes(db, folder, node_table, node_master):\n",
    "    # prep dict to write to csv\n",
    "    x = [[node, node_master[node]] for node in node_master]\n",
    "    # write out data\n",
    "    write_csv(os.path.join(folder, \"nodeMaster.csv\"), x)#, ['nodeid', 'masterid'])\n",
    "    # create temp_table\n",
    "    db.query('drop table if exists nodeMaster; CREATE TABLE nodeMaster (nodeid numeric(10,0), masterid numeric(10,0))')\n",
    "    \n",
    "    import_table(db, 'nodeMaster', os.path.join(folder, 'nodeMaster.csv'))\n",
    "#     raw_input(\n",
    "#         \"\"\"PG Console \\n\\n \\copy nodeMaster FROM '%s\\ nodeMaster.csv' DELIMITERS ',' CSV HEADER;\\n\\nDone?\"\"\" % folder)\n",
    "#     clear_output()\n",
    "\n",
    "    db.query(\"\"\"update %s\n",
    "                set masterid = nm.masterid\n",
    "                from nodemaster as nm\n",
    "                where node.nodeid = nm.nodeid\n",
    "                \"\"\" % node_table)\n",
    "    db.query('drop table nodemaster')\n",
    "\n",
    "update_db_nodes(db, params.FOLDER, params.NODE, params.node_master)  # 63.31 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query_to_table(db, \"select * from {} where masterid is not null limit 10\".format(params.NODE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nodes = [46535,46607,46609,46610,46612,46545]\n",
    "\n",
    "def get_center(db, nodes):\n",
    "    # get map center \n",
    "    data, col = db.query(\"\"\"select\n",
    "                        st_y(st_transform(st_centroid(st_union(geom)),4326)), \n",
    "                        st_x(st_transform(st_centroid(st_union(geom)),4326))\n",
    "                        from node where nodeid in ({})\"\"\".format(str(nodes)[1:-1]))\n",
    "    cent_ln, cent_lt = data[0]\n",
    "    return cent_ln, cent_lt \n",
    "\n",
    "    \n",
    "def map_nodes_is_int(db, nodes):\n",
    "    cent_ln, cent_lt  = get_center(db, nodes) \n",
    "    # create map object \n",
    "    Map = folium.Map(location=[cent_ln,cent_lt], \n",
    "                       tiles='Stamen Terrain',\n",
    "                       zoom_start=18)\n",
    "    # get nodes geom\n",
    "    data, col = db.query(\"\"\"select nodeid, is_int, masterid,\n",
    "                         st_y(st_transform(geom, 4326)) as y, \n",
    "                         st_x(st_transform(geom, 4326)) as x \n",
    "                         from node where nodeid in ({})\"\"\".format(str(nodes)[1:-1]))\n",
    "    # add nodes to map\n",
    "    for (node, is_int, master, lon, lat) in data:\n",
    "        m = params.node_master[46609] # same master\n",
    "        if master == m:\n",
    "            c = 'red'\n",
    "        else:\n",
    "            c = '#3186cc'\n",
    "        folium.CircleMarker(location=[lon, lat], \n",
    "                        radius=10,\n",
    "                        popup='point {}'.format(master), \n",
    "                        color=c,\n",
    "                        fill_color=c).add_to(Map)\n",
    "    #display map \n",
    "    return Map\n",
    "map_nodes_is_int(db, nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def simple_from_to_masters(db, lion, node):\n",
    "    print 'Updating Master From/To segments'\n",
    "    # update the from nodes for simple streets\n",
    "    # update the to nodes for simple streets\n",
    "\n",
    "    # make the min master as from and the max master as to\n",
    "    db.query(\"\"\"drop table if exists tempFrom; create table tempFrom as (\n",
    "                    select p1.mft, mn, mx from (\n",
    "                    select mft, min(masterid) as mn from (\n",
    "                    select mft, masterid \n",
    "                    from {0} as l\n",
    "                    join {1} as n\n",
    "                    on nodeidfrom::int = nodeid\n",
    "                    where mft is not null and masterid is not null\n",
    "                union\n",
    "                    select mft, masterid \n",
    "                    from {0} as l\n",
    "                    join {1} as n\n",
    "                    on nodeidto::int = nodeid\n",
    "                    where mft is not null and masterid is not null\n",
    "                    ) as mn group by mft\n",
    "                    ) as p1\n",
    "                    join (\n",
    "\n",
    "                    select mft, max(masterid) as mx from (\n",
    "                    select mft, masterid \n",
    "                    from {0} as l\n",
    "                    join {1} as n\n",
    "                    on nodeidfrom::int = nodeid\n",
    "                    where mft is not null and masterid is not null\n",
    "                union\n",
    "                    select mft, masterid \n",
    "                    from {0} as l\n",
    "                    join {1} as n\n",
    "                    on nodeidto::int = nodeid\n",
    "                    where mft is not null and masterid is not null\n",
    "                    ) as mx group by mft) as p2\n",
    "                    on p1.mft = p2.mft\n",
    "                    );\n",
    "                    \"\"\".format(lion, node))\n",
    "    # update lion with mfrom and to values\n",
    "    db.query(\"\"\"update %s as l\n",
    "                    set masteridfrom = mn, masteridto= mx\n",
    "                    from tempFrom\n",
    "                    where l.mft = tempFrom.mft \n",
    "                    \"\"\" % lion)\n",
    "    db.query(\"drop table tempFrom \")\n",
    "\n",
    "simple_from_to_masters(db, params.LION, params.NODE)  # 111.35 sec\n",
    "\n",
    "query_to_table(db, \"select * from {} where street = 'QUEENS BOULEVARD' limit 10\".format(params.LION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@timeDec\n",
    "def get_mfts(db, lion):\n",
    "    # go through list fo mfts\n",
    "    data = db.query(\n",
    "        \"\"\"select mft from {0} where exclude = 0\n",
    "             group by mft\n",
    "        \"\"\".format(lion))\n",
    "    # and (masteridfrom is null or masteridto is null)\n",
    "    local_mfts = [i[0] for i in data[0]]\n",
    "    return local_mfts\n",
    "\n",
    "\n",
    "l_mfts = get_mfts(db, params.LION)  # 0.56 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def make_c_master_seg_table(db, node_table, srid):\n",
    "    print 'Making new table'\n",
    "\n",
    "    db.query(\"drop table if exists c_master_segs\")\n",
    "    db.query(\"\"\"CREATE TABLE c_master_segs ( \n",
    "              mft    INTEGER,\n",
    "              street    varchar(100),\n",
    "              segmentid    varchar(10),\n",
    "              geom    geometry(LINESTRING, %i),\n",
    "              masteridfrom    INTEGER, \n",
    "              masteridto    INTEGER,\n",
    "              seg_cnt INTEGER\n",
    "              );\"\"\" % srid)\n",
    "\n",
    "    db.query(\"drop table if exists c_master_node\")\n",
    "    db.query(\"\"\"create table c_master_node as (\n",
    "                select distinct masterid,\n",
    "                        st_centroid(st_union(geom)) as geom,\n",
    "                        st_x(st_centroid(st_union(geom))) as centerX,\n",
    "                        st_y(st_centroid(st_union(geom))) as centerY,\n",
    "                        count(*)::int as nodes\n",
    "                from %s \n",
    "                where masterid !=0\n",
    "                group by  masterid\n",
    "                )\"\"\" % node_table)\n",
    "\n",
    "make_c_master_seg_table(db, params.NODE, params.SRID)  # 1.58 sec\n",
    "query_to_table(db, \"select * from c_master_node limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def mft_round2(db, lion):\n",
    "    print 'Updating mft (round 2)'\n",
    "    # make temp table for segs with same from and to masters and update lion with results\n",
    "    db.query(\"\"\"drop table if exists _temp_mft_update_;\n",
    "\n",
    "                create table _temp_mft_update_ as (\n",
    "                select min(mft) as mft,masteridfrom, masteridto\n",
    "                from {0}\n",
    "                where mft is not null and masteridfrom is not null and masteridto is not null\n",
    "                group by masteridfrom, masteridto);\n",
    "\n",
    "                update {0} as l\n",
    "                set mft = t.mft\n",
    "                from _temp_mft_update_ as t\n",
    "                where l.masteridfrom = t.masteridfrom\n",
    "                and l.masteridto = t.masteridto;\n",
    "\n",
    "                drop table if exists _temp_mft_update_;\n",
    "                \"\"\".format(lion))\n",
    "\n",
    "# TODO seems to be missing master segs for park ave BK, but the data is valid in lion and lion tamed\n",
    "mft_round2(db, params.LION)  # 63.77 sec\n",
    "\n",
    "query_to_table(db, \"select * from {} where street = 'QUEENS BOULEVARD' and rb_layer in ('B', 'G') limit 10\".format(params.LION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_dictionaries('OUT')  # 10.07 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Part 8\n",
    "### update database with final data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run to read saved data back into memory \n",
    "\n",
    "params.nodeStreetNames, params.nodeIsIntersection, params.nodeNextSteps, params.segmentBlocks, params.nodeMaster, params.clusterIntersections, params.streetSet, params.mft1Dict, params.altGraph, params.mfts, params.coordFromMaster = save_dictionaries('IN') #8.23 se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_simple_segs(db, node_table):\n",
    "    data = db.query(\"\"\"select mft, st_astext(ST_LineMerge(geom)), simple.masterid,simple2.masterid\n",
    "                from lion\n",
    "                ,(\n",
    "                    select n.nodeid::int, n.masterid\n",
    "                    from {0} as n\n",
    "                    join c_master_node\n",
    "                    on n.masterid = c_master_node.masterid\n",
    "                    where n.geom =c_master_node.geom\n",
    "                ) as simple\n",
    "                ,(\n",
    "                    select n.nodeid::int, n.masterid\n",
    "                    from {0} as n\n",
    "                    join c_master_node\n",
    "                    on n.masterid = c_master_node.masterid\n",
    "                    where n.geom =c_master_node.geom\n",
    "                ) as simple2\n",
    "                where nodeidfrom::int = simple.nodeid and nodeidto::int = simple2.nodeid\n",
    "                \"\"\".format(node_table))\n",
    "    simple_mfts = set()\n",
    "    line = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for row in bar(data[0]):\n",
    "        mft, mft_line, mfrom, mto = row\n",
    "        simple_mfts.add(mft)\n",
    "        line.append([mft, mft_line, mfrom, mto])\n",
    "    return simple_mfts, line\n",
    "\n",
    "\n",
    "def get_compex_segs(db, lion):\n",
    "    # create table with a count of verticies where are more than 2 so they can be remapped\n",
    "    db.query(\"\"\"drop table if exists complexSegs; create table complexSegs as (\n",
    "                    select mft, max(pos)\n",
    "                    from (\n",
    "                            select mft, \n",
    "                            (ST_DumpPoints(ST_LineMerge(ST_Union(geom)))).path[1] as pos\n",
    "                            from %s\n",
    "                            group by  mft\n",
    "                                    )as mx\n",
    "                    where mft is not null\n",
    "                    group by mft\n",
    "                    having max(pos) > 2 ) \"\"\" % lion)\n",
    "    # store the mfts that need to be remapped\n",
    "    data = db.query(\"select mft from complexSegs\")\n",
    "    to_do = set()\n",
    "    for mft in data[0]:\n",
    "        to_do.add(mft[0])\n",
    "    return to_do\n",
    "\n",
    "\n",
    "def coord_from_master_qry(db, coordFromMaster):\n",
    "    \n",
    "    data = db.query(\"select  masterid, st_x(geom), st_y(geom) from c_master_node\")\n",
    "    for row in data[0]:\n",
    "        master, x, y = row\n",
    "        coordFromMaster[master] = [x, y]\n",
    "    return coordFromMaster\n",
    "\n",
    "\n",
    "def get_geom(db, lion):\n",
    "    d = {}\n",
    "    data = db.query(\"\"\"select mft, ST_asText(ST_LineMerge(ST_Union(geom))) as g\n",
    "                ,masteridfrom, masteridto\n",
    "                from %s\n",
    "                where mft is not null and masteridfrom is not null and masteridto is not null\n",
    "                group by mft, masteridfrom, masteridto;\n",
    "                \"\"\" % lion)\n",
    "    for output in data[0]:\n",
    "        mft, geom, mfrom, mto = output\n",
    "        d[mft] = [geom, mfrom, mto]\n",
    "    return d\n",
    "\n",
    "def simple_new_ends(coordFromMaster, p1, p2):\n",
    "    return \"LINESTRING (%s %s, %s %s)\" % (str(coordFromMaster[p1][0]), str(coordFromMaster[p1][1]),\n",
    "                                          str(coordFromMaster[p2][0]), str(coordFromMaster[p2][1]))\n",
    "\n",
    "\n",
    "def simplify_coord(wkt):\n",
    "    x = str(wkt.split(\"(\")[1]).split(\")\")[0]\n",
    "    if \",\" not in x:\n",
    "        x = x.replace(\"[\", '').replace(\" \", \",\")\n",
    "    return [float(i) for i in x.split(\",\")]\n",
    "\n",
    "def clean(pt):\n",
    "    if type(pt) != list:\n",
    "        return [simplify_coord(pt)[0], simplify_coord(pt)[1]]\n",
    "    else:\n",
    "        return pt\n",
    "\n",
    "def coord_to_wkt(coord):\n",
    "    coord = str(coord)[1:-1].replace(\",\", \"\")\n",
    "    return \"POINT(\" + coord + \")\"\n",
    "\n",
    "def get_new_ends(db, geom, lion, coordFromMaster):\n",
    "    # store midles\n",
    "    d = {}  # {mft: [1st vertex, 2nd vertex...]}\n",
    "    # get geom without first or last vetex\n",
    "    data = db.query(\"\"\"select t.mft, pos, st_astext(geom )\n",
    "                    from (\n",
    "                        select mft,\n",
    "                        (ST_DumpPoints(ST_LineMerge(ST_Union(geom)))).path[1] as pos\n",
    "                        , (ST_DumpPoints(ST_LineMerge(ST_Union(geom)))).geom as geom\n",
    "                        from %s\n",
    "                        where masteridfrom is not null and masteridto is not null \n",
    "                        group by mft\n",
    "                    ) as t\n",
    "                    join complexSegs as cs \n",
    "                    on t.mft=cs.mft\n",
    "                    where pos > 1 and pos < cs.max\"\"\" % lion)\n",
    "    for row in data[0]:\n",
    "        mft, pos, coord = row\n",
    "        if mft not in d.keys():\n",
    "            d[mft] = [coord]\n",
    "        else:\n",
    "            d[mft].append(coord)\n",
    "    # find closest end point to from or to\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for mft in bar(d.keys()):\n",
    "        start = clean(d[mft][0])\n",
    "        end = clean(d[mft][-1])\n",
    "        frm = clean(coordFromMaster[geom[mft][1]])\n",
    "        to = clean(coordFromMaster[geom[mft][2]])\n",
    "        # check if only 1 vertex left and rebuild collection\n",
    "        if start == end:\n",
    "            d[mft] = [coord_to_wkt(frm), coord_to_wkt(start), coord_to_wkt(to)]\n",
    "        else:\n",
    "            # check if start is closer to from or to\n",
    "            dist = distance(start[0], start[1], frm[0], frm[1])  # SF\n",
    "            if distance(start[0], start[1], to[0], to[1]) < dist:  # ST\n",
    "                dist = distance(start[0], start[1], to[0], to[1])\n",
    "                # start is closer to to, but need to check that start/to is closer that end/to\n",
    "                if distance(end[0], end[1], to[0], to[1]) < dist:  # ET\n",
    "                    d[mft] = [coord_to_wkt(frm)] + d[mft] + [coord_to_wkt(to)]\n",
    "                else:\n",
    "                    d[mft] = [coord_to_wkt(to)] + d[mft] + [coord_to_wkt(frm)]  # ST\n",
    "            else:  # SF\n",
    "                # start is closer to frm, but need to check that start/frm is closer that start/frm\n",
    "                if distance(end[0], end[1], frm[0], frm[1]) < dist:  # EF\n",
    "                    d[mft] = [coord_to_wkt(to)] + d[mft] + [coord_to_wkt(frm)]  # ST\n",
    "                else:\n",
    "                    d[mft] = [coord_to_wkt(frm)] + d[mft] + [coord_to_wkt(to)]  # SF\n",
    "        # clean up and make line\n",
    "        # print 'Finishing mft %i' %(mft)\n",
    "        d[mft] = line_from_pts(d[mft]).replace(\"'\", \"\")\n",
    "    return d\n",
    "\n",
    "def line_from_pts(wkt_list):\n",
    "    out = 'LINESTRING('\n",
    "\n",
    "    def simple(pt):\n",
    "        return [float(j) for j in pt.split(\"(\")[1].split(\")\")[0].split(\" \")]\n",
    "\n",
    "    for i in wkt_list:\n",
    "        out = out + str(simple(i)[0]) + \" \" + str(simple(i)[1]) + \", \"\n",
    "    return out[:-2] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@timeDec\n",
    "def remap(db, folder, node_table, lion, srid, coordFromMaster):\n",
    "    # change insert 1 row at a time to csv io model\n",
    "    simple_mfts, list_c_master_segs = get_simple_segs(db, node_table)\n",
    "    complex_mfts = get_compex_segs(db, lion)\n",
    "    # get coordinates for new end points\n",
    "    params.coordFromMaster = coord_from_master_qry(db, params.coordFromMaster)\n",
    "    # get basic info for corridors\n",
    "    geom = get_geom(db, lion)\n",
    "    counter = 0\n",
    "    print 'found %i segments that are simple and do not need remapping' % (len(list_c_master_segs))\n",
    "    todo = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for mft in bar(geom.keys()):\n",
    "        if mft in simple_mfts:\n",
    "            # no change needed\n",
    "            pass\n",
    "        elif mft in complex_mfts:\n",
    "            # check if simple or complex change\n",
    "            pass\n",
    "        else:\n",
    "            todo.append(mft)\n",
    "    for mft in todo:\n",
    "        geo, mfrom, mto = geom[mft]\n",
    "        if 'MULTILINESTRING' in geo:\n",
    "            pass\n",
    "        elif mft and mfrom and mto:\n",
    "            # simple straight  line, just use master from/to as new coordinates\n",
    "            list_c_master_segs.append([mft, simple_new_ends(coordFromMaster, mfrom, mto), mfrom, mto])\n",
    "\n",
    "    complex_geom = get_new_ends(db, geom, lion, coordFromMaster)\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for mft in bar(complex_geom.keys()):\n",
    "        new_geom, mfrom, mto = complex_geom[mft], geom[mft][1], geom[mft][2]\n",
    "        # change insert 1 row at a time to csv io model\n",
    "        if 'MULTILINESTRING' in new_geom:\n",
    "            pass\n",
    "        else:\n",
    "            list_c_master_segs.append([mft, new_geom, mfrom, mto])\n",
    "            counter += 1\n",
    "    db.query(\"drop table complexSegs\")\n",
    "\n",
    "    print 'done re-mapping %i sgements' % counter\n",
    "    write_csv(os.path.join(folder, \"tempMaster.csv\"), list_c_master_segs, None, ';')#, ['mft', 'mftLine', 'mfrom', 'mto'])\n",
    "    db.query(\"drop table if exists tempMaster; CREATE TABLE tempMaster (mft int, mftLine text, mfrom int, mto int)\")\n",
    "    import_table(db, 'tempMaster', os.path.join(folder, 'tempMaster.csv'),';')\n",
    "#      raw_input(\n",
    "#          \"\"\"PG Console \\n\\n \\copy tempMaster FROM '%s\\\\tempMaster.csv' DELIMITERS ',' CSV HEADER;\\n\\nDone?\"\"\" % folder)\n",
    "#     clear_output()\n",
    "    db.query(\"\"\"insert into c_master_segs (mft, geom, masteridfrom, masteridto)\n",
    "                ((select mft, st_geomfromtext(mftLine, %i), mfrom, mto from tempMaster\n",
    "                where mft is not null group by mft, mftline, mfrom, mto))\"\"\" % srid)\n",
    "    db.query(\"drop table tempMaster\")\n",
    "\n",
    "remap(db, params.FOLDER, params.NODE, params.LION, params.SRID, params.coordFromMaster)  # 122.62 sec\n",
    "\n",
    "query_to_table(db, \"select * from c_master_segs limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def update_c_master_segs(db, lion):\n",
    "    db.query(\"\"\"update c_master_segs as ms\n",
    "                    set segmentid = q.segmentid,street = q.street\n",
    "                    from \n",
    "                    (\n",
    "                    select street, lion.segmentid , lion.mft\n",
    "                    from {0} \n",
    "                    , (\n",
    "                            select mft, segmentid, max(st_length(geom)) as ml\n",
    "                            from {0}\n",
    "                            group by mft, segmentid, st_length(geom)\n",
    "                    ) as mln\n",
    "                    where {0}.segmentid = mln.segmentid\n",
    "                    group by street, {0}.segmentid , {0}.mft\n",
    "                    ) as q\n",
    "                    where ms.mft=q.mft\n",
    "                \"\"\".format(lion))\n",
    "    db.query(\"\"\"update c_master_segs as ms\n",
    "                    set seg_cnt = cnt\n",
    "                    from \n",
    "                    (\n",
    "                            select mft, count(*) as cnt from %s group by mft\n",
    "                    ) as q\n",
    "                    where ms.mft=q.mft;\n",
    "                \"\"\" % lion)\n",
    "\n",
    "update_c_master_segs(db, params.LION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stringify(int_to_sting, length):\n",
    "    int_to_sting = str(int_to_sting)\n",
    "    if len(int_to_sting) == length:\n",
    "        return int_to_sting\n",
    "    else:\n",
    "        return stringify(\"0\" + int_to_sting, length)\n",
    "    \n",
    "@timeDec\n",
    "def update_roadbeds(db, folder, lion, tbl_rpl):\n",
    "    data = db.query(\"select segmentid, mft from %s where mft is not null\" % lion)\n",
    "    seg_mft = {}\n",
    "    to_test = set()\n",
    "    for i in data[0]:\n",
    "        seg, mft = i\n",
    "        seg_mft[seg] = mft\n",
    "\n",
    "    data = db.query(\"\"\"select segmentid, other from (\n",
    "                    select segmentid, segmentidg as other \n",
    "                    from {0} as l\n",
    "                    join {1} on l.segmentid::int = segmentidr \n",
    "                    union\n",
    "                    select segmentid, segmentidr as other \n",
    "                    from {0} as l\n",
    "                    join {1} on l.segmentid::int = segmentidg\n",
    "                    ) as base group by segmentid, other\n",
    "                     \"\"\".format(lion, tbl_rpl))\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for row in bar(data[0]):\n",
    "        seg1, seg2 = row[0], stringify(row[1], 7)\n",
    "        if seg1 in seg_mft.keys():\n",
    "            # seg2 might not be in the dict\n",
    "            if seg2 not in seg_mft.keys():\n",
    "                # add rb to dict with centerline mft\n",
    "                seg_mft[seg2] = seg_mft[seg1]\n",
    "        elif seg2 in seg_mft.keys():\n",
    "            # seg2 might not be in the dict\n",
    "            if seg1 not in seg_mft.keys():\n",
    "                # add rb to dict with centerline mft\n",
    "                seg_mft[seg1] = seg_mft[seg2]\n",
    "        else:\n",
    "            to_test.add(seg1)\n",
    "            to_test.add(seg2)\n",
    "\n",
    "    print 'Still missing %i segments\\n' % (len(to_test))\n",
    "    out = [[key, seg_mft[key]] for key in seg_mft]\n",
    "\n",
    "    write_csv(os.path.join(folder, \"tempMaster.csv\"), out)#, ['Segmentid', 'MFT'])\n",
    "\n",
    "    db.query(\"drop table if exists tempMaster; CREATE TABLE tempMaster (Segmentid int, MFT int)\")\n",
    "\n",
    "    import_table(db, 'tempMaster', os.path.join(folder, 'tempMaster.csv'))\n",
    "#     raw_input(\n",
    "#         \"\"\"PG Console \\n\\n \\copy tempMaster FROM '%s\\\\tempMaster.csv' DELIMITERS ',' CSV HEADER;\\n\\nDone?\"\"\" % folder)\n",
    "#     clear_output()\n",
    "    db.query(\"\"\"update %s as l\n",
    "                    set mft = t.mft\n",
    "                    from tempMaster as t\n",
    "                    where l.segmentid::int = t.segmentid\n",
    "                    and l.mft is null\"\"\" % lion)\n",
    "\n",
    "    db.query(\"drop table tempMaster\")\n",
    "\n",
    "    db.query(\"\"\"update %s as l\n",
    "                    set masteridfrom = m.masteridfrom, masteridto = m.masteridto\n",
    "                    from c_master_segs as m\n",
    "                    where l.mft = m.mft\"\"\" % lion)\n",
    "\n",
    "update_roadbeds(db, params.FOLDER, params.LION, params.RPL)  # 1302.61 sec\n",
    "query_to_table(db, \"select * from c_master_segs limit 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@timeDec\n",
    "def update_roadbed_nodes(db, node_table, tbl_rpl):\n",
    "    db.query(\"\"\"create table m as (\n",
    "                select n.nodeid, nn.masterid\n",
    "                    from {0} as n\n",
    "                    join {1} as t\n",
    "                        on n.nodeid=t.r_tond\n",
    "                    join {0} as nn\n",
    "                        on g_tond = nn.nodeid\n",
    "                    where n.masterid is null and nn.masterid is not null\n",
    "                union\n",
    "                    select n.nodeid, nn.masterid\n",
    "                    from {0} as n\n",
    "                    join {1} as t\n",
    "                        on n.nodeid=t.g_tond\n",
    "                    join {0} as nn\n",
    "                        on r_tond = nn.nodeid\n",
    "                    where n.masterid is null and nn.masterid is not null\n",
    "                union\n",
    "                    select n.nodeid, nn.masterid\n",
    "                    from {0} as n\n",
    "                    join {1} as t\n",
    "                        on n.nodeid=t.r_frnd\n",
    "                    join {0} as nn\n",
    "                        on g_frnd = nn.nodeid\n",
    "                    where n.masterid is null and nn.masterid is not null\n",
    "                union\n",
    "                    select n.nodeid, nn.masterid\n",
    "                    from {0} as n\n",
    "                    join {1} as t\n",
    "                        on n.nodeid=t.g_frnd\n",
    "                    join {0} as nn\n",
    "                        on r_frnd = nn.nodeid\n",
    "                    where n.masterid is null and nn.masterid is not null)\n",
    "                \"\"\".format(node_table, tbl_rpl))\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        db.query(\"\"\"update %s as n\n",
    "                    set masterid = m.masterid\n",
    "                    from m\n",
    "                    where n.nodeid=m.nodeid and n.masterid is null\"\"\" % node_table)\n",
    "    db.query(\"drop table m\")\n",
    "    db.query(\"\"\"update {0} as n\n",
    "                    set masterid  = nn.masterid\n",
    "                    from (\n",
    "                        select distinct r,g from (\n",
    "                        select r_frnd as r, g_frnd as g\n",
    "                        from {1}\n",
    "                        union\n",
    "                        select r_tond as r, g_tond as g\n",
    "                        from {1}\n",
    "                        ) as passthrough\n",
    "                    )as nl, {0} as nn\n",
    "                    where n.nodeid::int = r::int\n",
    "                    and  g::int = nn.nodeid::int\n",
    "                    and n.masterid is null and nn.masterid is not null\n",
    "                \"\"\".format(node_table, tbl_rpl))\n",
    "    db.query(\"\"\"update {0} as n\n",
    "                    set masterid  = nn.masterid\n",
    "                    from (\n",
    "                        select distinct r,g from (\n",
    "                        select r_frnd as r, g_frnd as g\n",
    "                        from {1}\n",
    "                        union\n",
    "                        select r_tond as r, g_tond as g\n",
    "                        from {1}\n",
    "                        ) as passthrough\n",
    "                    )as nl, {0} as nn\n",
    "                    where n.nodeid::int = g::int\n",
    "                    and  r::int = nn.nodeid::int\n",
    "                    and n.masterid is null and nn.masterid is not null\n",
    "                \"\"\".format(node_table, tbl_rpl))\n",
    "    \n",
    "update_roadbed_nodes(db, params.NODE, params.RPL)\n",
    "query_to_table(db, \"select * from {0} limit 10\".format(params.NODE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regenerate MFTs to be longest segment and MasterIDs for most central NodeID to allow for continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_new_mft_lookup(db, lion):\n",
    "    db.query(\"drop table if exists temp_new_mfts;\")\n",
    "    db.query(\"\"\"create table temp_new_mfts as \n",
    "                select min(segmentid) as seg, l.mft from {0} l join (\n",
    "                    select mft, max(st_length(geom)) as mxl from {0} where mft is not null group by mft\n",
    "                    ) as ml on l.mft = ml.mft and st_length(l.geom) = ml.mxl\n",
    "                group by l.mft;\n",
    "            \"\"\".format(lion))\n",
    "        \n",
    "def make_new_masternode_lookup(db, node):\n",
    "    db.query(\"drop table if exists temp_new_masters;\")\n",
    "    db.query(\"\"\"create table temp_new_masters as \n",
    "                select d.* \n",
    "                from (\n",
    "                select n.masterid, min(st_distance(n.geom, c.geom)) as mdist\n",
    "                from {0} n join c_master_node as c on n.masterid = c.masterid\n",
    "                group by n.masterid\n",
    "                ) md join (\n",
    "                select nodeid, n.masterid, st_distance(n.geom, c.geom) as dist\n",
    "                from {0} n join c_master_node as c on n.masterid = c.masterid\n",
    "                ) d on md.masterid = d.masterid and mdist = dist\n",
    "            \"\"\".format(node))\n",
    "\n",
    "def update_tables_masters(db, lion, node):\n",
    "    mft_tables = ['c_master_segs', lion]\n",
    "    master_n_tables = [node, 'c_master_node']\n",
    "    for t in mft_tables:\n",
    "        db.query(\"\"\"update {} t set mft = n.seg::int \n",
    "                    from temp_new_mfts n where t.mft = n.mft\n",
    "                \"\"\".format(t))\n",
    "        db.query(\"\"\"update {} t set masteridfrom = n.nodeid::int\n",
    "                    from temp_new_masters n where t.masteridfrom = n.masterid\n",
    "                    \"\"\".format(t))\n",
    "        db.query(\"\"\"update {} t set masteridto = n.nodeid::int\n",
    "                    from temp_new_masters n where t.masteridto = n.masterid\n",
    "                    \"\"\".format(t))\n",
    "    for t in master_n_tables:\n",
    "        db.query(\"\"\"update {} t set masterid = n.nodeid::int \n",
    "                    from temp_new_masters n where t.masterid = n.masterid\n",
    "                \"\"\".format(t))\n",
    "\n",
    "make_new_mft_lookup(db, params.LION)\n",
    "make_new_masternode_lookup(db, params.NODE)\n",
    "update_tables_masters(db,  params.LION, params.NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print db.query(\"select * from temp_new_mfts where mft = 109072\")\n",
    "print db.query(\"select * from temp_new_masters where masterid = 9683\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_centerline_clean(db, lion, node_table, version):\n",
    "    db.query(\"\"\"drop table if exists C_Lion_{0}; create table C_Lion_{0} as (\n",
    "                    select distinct *\n",
    "                    from {1}\n",
    "                    where exclude = 0 and mft is not null\n",
    "                    )\"\"\".format(version, lion))\n",
    "\n",
    "    db.query(\"\"\"drop table if exists C_Lion_Nodes_{0}; create table C_Lion_Nodes_{0} as (\n",
    "                    select distinct *\n",
    "                    from {1}\n",
    "                    where is_int =-1\n",
    "                    )\"\"\".format(version, node_table))\n",
    "    print '\\nDONE!\\n'\n",
    "\n",
    "make_centerline_clean(db, params.LION, params.NODE, params.VERSION)\n",
    "\n",
    "query_to_table(db, \"select * from  C_Lion_{0} limit 10\".format(params.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@timeDec\n",
    "def add_boroughs_to_intersections(db, version, boroughs):\n",
    "    nodes = 'C_Lion_nodes_' + version\n",
    "    print 'Updating boroughs for nodes\\n'\n",
    "    db.query(\"\"\"alter table {0} drop column if exists lboro;\n",
    "                    alter table {0} drop column if exists rboro;\n",
    "                    alter table {0} add column lboro int;\n",
    "                    alter table {0} add column rboro int;\n",
    "                    \"\"\".format(nodes))\n",
    "\n",
    "    db.query(\"\"\"update %s as n\n",
    "                    set lboro = borocode\n",
    "                    from %s as b\n",
    "                    where st_dwithin(n.geom, b.geom, 5)\n",
    "                    and lboro is null;\"\"\" % (nodes, boroughs))\n",
    "    db.query(\"\"\"update %s as n\n",
    "                    set rboro = borocode\n",
    "                    from %s as b\n",
    "                    where st_dwithin(n.geom, b.geom, 5)\n",
    "                    and rboro is null;\"\"\" % (nodes, boroughs))\n",
    "\n",
    "add_boroughs_to_intersections(db, params.VERSION, params.BOROUGHS)  # 400.35 sec\n",
    "query_to_table(db, \"select * from  C_Lion_nodes_{0} limit 10\".format(params.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_nodes(db, node_table):\n",
    "    data = db.query(\n",
    "        \"select count(*) from (select distinct masterid from %s where masterid is not null) as t\" % node_table)\n",
    "    return data[0][0]\n",
    "\n",
    "@timeDec\n",
    "def make_lookup(db, node_table, lion_table, ver):\n",
    "    db.query(\"drop table if exists c_lion_node_lookup\")\n",
    "\n",
    "    db.query('''create table c_lion_node_lookup as (\n",
    "                select nodeid, masterid, mft, segmentid\n",
    "                from %s as l\n",
    "                join %s as n\n",
    "                 on l.nodeidfrom::int = n.nodeid\n",
    "                union\n",
    "                select nodeid, masterid, mft, segmentid\n",
    "                from %s as l\n",
    "                join %s as n\n",
    "                 on l.nodeidto::int = n.nodeid\n",
    "                ) ''' % (lion_table, node_table, lion_table, node_table))\n",
    "    # index lookup\n",
    "    version = 'C_Lion_nodes_'+ver\n",
    "    index_list = [\"drop index if exists nd_IDX; \", \"drop index if exists master_IDX;\", \"drop index if exists mft_IDX;\",\n",
    "                  \"drop index if exists seg_IDX;\", \"drop index if exists lt_node_IDX\",\n",
    "                  \"CREATE INDEX nd_IDX ON c_lion_node_lookup (nodeid);\",\n",
    "                  \"CREATE INDEX master_IDX ON c_lion_node_lookup (masterid);\",\n",
    "                  \"CREATE INDEX mft_IDX ON c_lion_node_lookup (mft);\",\n",
    "                  \"CREATE INDEX seg_IDX ON c_lion_node_lookup (segmentid);\",\n",
    "                  \"CREATE INDEX lt_node_IDX ON %s (nodeid);\" % version]\n",
    "    for idx in index_list:\n",
    "        db.query(idx)\n",
    "\n",
    "make_lookup(db, params.NODE, params.LION, params.VERSION)  # 122.01 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# clean up directory \n",
    "\n",
    "for f in os.listdir(params.FOLDER):\n",
    "    if f.endswith(('.csv','.p')):\n",
    "        print 'Deleting {}...'.format(f)\n",
    "        os.remove(f)\n",
    "        \n",
    "        \n",
    "# grant permissions\n",
    "tables = ['node_stnameft', 'lion', 'node', 'c_master_node',\n",
    "              'c_master_segs', 'C_Lion_%s' % params.VERSION, 'C_Lion_Nodes_%s' % params.VERSION]\n",
    "for t in tables:\n",
    "    db.query('grant all on {} to public'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_mileage(db, lion):\n",
    "    miles = {}\n",
    "    for b in range(1, 6):\n",
    "        data = db.query(\"\"\"select sum(st_length(geom))/5280 from (\n",
    "                        select distinct on (segmentid) geom from {0}\n",
    "                        where exclude = 0\n",
    "                            and mft is not null\n",
    "                            and (lboro = {1} or rboro = {1} )\n",
    "                        group by segmentid, geom\n",
    "                    ) as singles\"\"\".format(lion, b, b))\n",
    "        miles[b] = data[0][0][0]\n",
    "    data = db.query(\"\"\"select sum(st_length(geom))/5280 from ( \n",
    "                    select distinct on (segmentid) geom from {0}\n",
    "                    where exclude = 0\n",
    "                        and mft is not null\n",
    "                    group by segmentid, geom\n",
    "                ) as singles\"\"\".format(lion))\n",
    "    miles[0] = data[0][0][0]\n",
    "    return miles\n",
    "\n",
    "miles = get_mileage(db, params.LION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print '-----------------------------------------------------------------------------------'\n",
    "print 'LION (Version {0}) files:\\nBasic ({1}, {2}), \\nUgly(c_master_segs, c_master_node), \\\n",
    "\\nCenterline(C_Lion{0}, C_Lion_Nodes_{0})'.format(\n",
    "    params.VERSION, params.LION, params.NODE)\n",
    "print '-----------------------------------------------------------------------------------'\n",
    "for i in miles:\n",
    "    if i > 0:\n",
    "        print 'Borough %i: %4.2f Miles of Centerline Non-Highway Roadway' % (i, miles[i])\n",
    "    else:\n",
    "        print 'Citywide: %4.2f Miles of Centerline Non-Highway Roadway' % (miles[i])\n",
    "print '%i Intersections' % (get_nodes(db, params.NODE))\n",
    "print '-----------------------------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = query_to_table(db,\"\"\"\n",
    "                    select lboro as Borough, sum(st_length(geom))/5280 as Miles from (\n",
    "                        select distinct on (segmentid) lboro, geom from {0}\n",
    "                        where exclude = 0\n",
    "                            and mft is not null\n",
    "                        group by segmentid, geom, lboro\n",
    "                    ) as singles group by lboro \"\"\".format(params.LION))\n",
    "\n",
    "cols = ['borough', 'miles']\n",
    "df = pd.DataFrame(df.to_dict(), columns=cols) # convert to pandas dataframe\n",
    "#print df\n",
    "\n",
    "labels = df['borough']\n",
    "sizes = df['miles']\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Miles by Borough\\n')\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.0f%%')#, startangle=70)\n",
    "ax1.axis('equal')  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
